{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from scipy.special import softmax\n",
    "from typing import List, Tuple, Iterator, Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text8.txt') as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17005207"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramNSDataIterator:\n",
    "    def __init__(self,\n",
    "                 corpus: str,\n",
    "                 window_size: int,\n",
    "                 batch_size: int,\n",
    "                 vocab_size: int = 100000,\n",
    "                 use_padding: bool = True,\n",
    "                 negative: int = 20) -> None:\n",
    "        self.corpus = self.__tokenize(corpus.strip())\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.use_padding = use_padding\n",
    "        self.negative = negative\n",
    "        \n",
    "        self.pad = '<PAD>'\n",
    "        self.unk = '<UNK>'\n",
    "        self.word2idx = {self.pad: 0, self.unk: 1}\n",
    "        self.idx2word = {0: self.pad, 1: self.unk}\n",
    "        self.distr = None\n",
    "        self.vocab_range = None\n",
    "        \n",
    "        self.__build_vocabulary()\n",
    "    \n",
    "    @staticmethod\n",
    "    def __tokenize(text: str) -> List[str]:\n",
    "        return text.split()\n",
    "    \n",
    "    def __build_vocabulary(self) -> None:\n",
    "        print(f'Bulding vocabulary of size {self.vocab_size}...')\n",
    "\n",
    "        word_counts = Counter(self.corpus)\n",
    "        vocab = [word for word, _ in sorted(word_counts.items(),\n",
    "                                            key=lambda x: x[1],\n",
    "                                            reverse=True)[:self.vocab_size - 2]]\n",
    "        self.distr = softmax(np.power(\n",
    "            (1 / np.array([word_counts[word] for word in vocab])), 0.75\n",
    "        ))\n",
    "        \n",
    "        for i, word in enumerate(vocab):\n",
    "            self.word2idx[word] = i+2\n",
    "            self.idx2word[i+2] = word\n",
    "        \n",
    "        self.vocab_size = len(vocab)+2\n",
    "        self.vocab_range = np.arange(self.vocab_size-2)\n",
    "        \n",
    "        print(f'Vocabulary built. Resulting size: {self.vocab_size}.')\n",
    "    \n",
    "    def __sample(self) -> np.ndarray:\n",
    "        return np.random.choice(self.vocab_range, size=self.negative, p=self.distr)\n",
    "    \n",
    "    def __preprocess_batch(self, batch: List[str], use_padding: Optional[bool] = None) -> torch.LongTensor:\n",
    "        if use_padding is None:\n",
    "            use_padding = self.use_padding\n",
    "        \n",
    "        if use_padding and len(batch) < self.window_size * 2:\n",
    "            batch = [self.pad] * ((self.window_size * 2) - len(batch)) + batch\n",
    "            \n",
    "        output = [self.word2idx.get(word, self.word2idx[self.unk]) for word in batch]\n",
    "            \n",
    "        return torch.LongTensor(output)\n",
    "    \n",
    "    def indices_to_words(self, indices: torch.LongTensor) -> List[str]:\n",
    "        return [[self.idx2word[idx] for idx in batch] for batch in indices]\n",
    "        \n",
    "    def generate_batch(self) -> Iterator[Tuple[torch.LongTensor, torch.Tensor]]:\n",
    "        batch_inp, batch_target = [], []\n",
    "        \n",
    "        for i, center in np.random.permutation(list(enumerate(self.corpus))):\n",
    "            i = int(i)\n",
    "            center_id = self.__preprocess_batch([center], use_padding=False)\n",
    "            for context_id in self.__preprocess_batch(\n",
    "                    self.corpus[max(i-self.window_size, 0):i] + self.corpus[i+1:i+self.window_size+1]):\n",
    "                batch_inp.append(torch.LongTensor([center_id, context_id]))\n",
    "                batch_target.append(1)\n",
    "                \n",
    "                if len(batch_inp) == self.batch_size:\n",
    "                    yield torch.stack(batch_inp), torch.Tensor(batch_target)\n",
    "                    batch_inp, batch_target = [], []\n",
    "            \n",
    "            for negative_id in self.__sample():\n",
    "                batch_inp.append(torch.LongTensor([center_id, negative_id+2]))\n",
    "                batch_target.append(0)\n",
    "                \n",
    "                if len(batch_inp) == self.batch_size:\n",
    "                    yield torch.stack(batch_inp), torch.Tensor(batch_target)\n",
    "                    batch_inp, batch_target = [], []\n",
    "                \n",
    "        yield torch.stack(batch_inp), torch.Tensor(batch_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramNSModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_size: int,\n",
    "                 vocab_size: int) -> None:\n",
    "        super().__init__()\n",
    "        self.__hidden_size = hidden_size\n",
    "        self.V = nn.Linear(vocab_size, hidden_size)\n",
    "        self.U = nn.Linear(vocab_size, hidden_size)\n",
    "        \n",
    "    def forward(self, center: torch.Tensor, context: torch.Tensor) -> torch.Tensor:\n",
    "        center_embedding = self.V(center)\n",
    "        context_embedding = self.U(context)\n",
    "        \n",
    "        return torch.bmm(center_embedding.view(-1, 1, self.__hidden_size),\n",
    "                         context_embedding.view(-1, self.__hidden_size, 1))[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramNSTrainer:\n",
    "    def __init__(self,\n",
    "                 corpus: str,\n",
    "                 window_size: int,\n",
    "                 hidden_size: int,\n",
    "                 vocab_size: int = 100000,\n",
    "                 use_padding: bool = True,\n",
    "                 negative: int = 20,\n",
    "                 batch_size: int = 2048,\n",
    "                 num_epochs: int = 10,\n",
    "                 learning_rate: float = 0.001,\n",
    "                 cuda_device: int = 0) -> None:\n",
    "        \n",
    "        self.iterator = SkipGramNSDataIterator(corpus, window_size, batch_size,\n",
    "                                               vocab_size, use_padding, negative)\n",
    "        self.vocab_size = self.iterator.vocab_size\n",
    "        self.model = SkipGramNSModel(hidden_size, self.vocab_size)\n",
    "        \n",
    "        self.device = torch.device(f'cuda:{cuda_device}') \\\n",
    "                if cuda_device >= 0 else torch.device('cpu')\n",
    "        if cuda_device >= 0:\n",
    "            self.model = self.model.cuda(self.device)\n",
    "        \n",
    "        self.num_epochs = num_epochs\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "    def train(self, print_every: int = 10000) -> List[torch.Tensor]:\n",
    "        \n",
    "        losses = []\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            total_loss = torch.Tensor([0])\n",
    "            print(f'Epoch {epoch+1}/{self.num_epochs}')\n",
    "            \n",
    "            for i, (inp, target) in enumerate(self.iterator.generate_batch()):\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                inp_var = autograd.Variable(\n",
    "                    F.one_hot(inp.to(self.device), self.vocab_size).float()\n",
    "                )\n",
    "                out = self.model(inp_var[:, 0, :].view(-1, self.vocab_size),\n",
    "                                 inp_var[:, 1, :].view(-1, self.vocab_size))\n",
    "                \n",
    "                loss = self.loss(out, target.to(self.device))\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.detach().item()\n",
    "                \n",
    "                if i % print_every == 0:\n",
    "                    print(f'{i} iterations... Current loss: {loss.detach().item():.2f}.')\n",
    "                    \n",
    "            losses.append(total_loss)\n",
    "            print()\n",
    "        \n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulding vocabulary of size 100000...\n",
      "Vocabulary built. Resulting size: 100000.\n"
     ]
    }
   ],
   "source": [
    "trainer = SkipGramNSTrainer(\n",
    "    corpus,\n",
    "    window_size=5,\n",
    "    hidden_size=100,\n",
    "    use_padding=False,\n",
    "    negative=5,\n",
    "    num_epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "0 iterations... Current loss: 0.69.\n",
      "10000 iterations... Current loss: 0.21.\n",
      "20000 iterations... Current loss: 0.20.\n",
      "30000 iterations... Current loss: 0.21.\n",
      "40000 iterations... Current loss: 0.21.\n",
      "50000 iterations... Current loss: 0.22.\n",
      "60000 iterations... Current loss: 0.20.\n",
      "70000 iterations... Current loss: 0.20.\n",
      "80000 iterations... Current loss: 0.18.\n",
      "90000 iterations... Current loss: 0.21.\n",
      "100000 iterations... Current loss: 0.19.\n",
      "110000 iterations... Current loss: 0.20.\n",
      "120000 iterations... Current loss: 0.19.\n",
      "\n",
      "Epoch 2/3\n",
      "0 iterations... Current loss: 0.19.\n",
      "10000 iterations... Current loss: 0.18.\n",
      "20000 iterations... Current loss: 0.20.\n",
      "30000 iterations... Current loss: 0.22.\n",
      "40000 iterations... Current loss: 0.18.\n",
      "50000 iterations... Current loss: 0.19.\n",
      "60000 iterations... Current loss: 0.20.\n",
      "70000 iterations... Current loss: 0.20.\n",
      "80000 iterations... Current loss: 0.17.\n",
      "90000 iterations... Current loss: 0.19.\n",
      "100000 iterations... Current loss: 0.21.\n",
      "110000 iterations... Current loss: 0.20.\n",
      "120000 iterations... Current loss: 0.18.\n",
      "\n",
      "Epoch 3/3\n",
      "0 iterations... Current loss: 0.19.\n",
      "10000 iterations... Current loss: 0.19.\n",
      "20000 iterations... Current loss: 0.18.\n",
      "30000 iterations... Current loss: 0.19.\n",
      "40000 iterations... Current loss: 0.18.\n",
      "50000 iterations... Current loss: 0.17.\n",
      "60000 iterations... Current loss: 0.17.\n",
      "70000 iterations... Current loss: 0.20.\n",
      "80000 iterations... Current loss: 0.21.\n",
      "90000 iterations... Current loss: 0.16.\n",
      "100000 iterations... Current loss: 0.17.\n",
      "110000 iterations... Current loss: 0.17.\n",
      "120000 iterations... Current loss: 0.18.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(trainer, word: str) -> np.ndarray:\n",
    "    idx = trainer.iterator.word2idx.get(word, None)\n",
    "    if idx is not None:\n",
    "        inp = torch.zeros(trainer.vocab_size)\n",
    "        inp[idx] = 1\n",
    "        inp = inp.to(trainer.device)\n",
    "        \n",
    "        return trainer.model.V(inp).detach().cpu().numpy() + \\\n",
    "                trainer.model.U(inp).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(trainer, words: List[str]) -> Tuple[np.ndarray, List[str]]:\n",
    "    embedding_matrix, words_found = [], []\n",
    "    \n",
    "    for word in words:\n",
    "        emb = get_embedding(trainer, word)\n",
    "        if emb is not None:\n",
    "            embedding_matrix.append(emb)\n",
    "            words_found.append(word)\n",
    "    \n",
    "    return np.vstack(embedding_matrix), words_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(trainer, words: List[str]):\n",
    "    pca = PCA(2)\n",
    "    embedding_matrix, words_found = get_embeddings(trainer, words)\n",
    "    embedding_pca = pca.fit_transform(embedding_matrix)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for word, embedding in zip(words_found, embedding_pca):\n",
    "        plt.scatter(embedding[0], embedding[1], marker='x', color='red')\n",
    "        plt.text(embedding[0] + 0.01, embedding[1] + 0.01, word, fontsize=9)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_embeddings(trainer, ['school', 'university', 'teacher', 'professor',\n",
    "                          'grade', 'paper', 'class', 'lesson', 'exam', 'prom',\n",
    "                          'academy', 'education', 'college', 'exams', 'gpa',\n",
    "                          'food', 'spaghetti', 'beer', 'wine', 'burger', 'steak'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrinsic evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack([\n",
    "    get_embedding(trainer, word) for word in trainer.iterator.word2idx\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19559/19559 [07:15<00:00, 44.96it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "with open('questions-words.txt', 'r') as f:\n",
    "    for line in tqdm(f.read().split('\\n')):\n",
    "        analogy = line.split()\n",
    "        if not analogy:\n",
    "            continue\n",
    "            \n",
    "        if ':' in line:\n",
    "            curr_topic = analogy[-1]\n",
    "            results[curr_topic] = {'total': 0, 'correct': 0}\n",
    "            continue\n",
    "            \n",
    "        if any(word.lower() not in trainer.iterator.word2idx for word in analogy):\n",
    "            continue\n",
    "\n",
    "        results[curr_topic]['total'] += 1\n",
    "        word1, word2, word3, word4 = analogy\n",
    "        candidate = (get_embedding(trainer, word2.lower()) - get_embedding(trainer, word1.lower()) +\n",
    "                     get_embedding(trainer, word3.lower())).reshape(1, -1)\n",
    "        closest = trainer.iterator.idx2word[\n",
    "            np.argmin(cdist(candidate, embedding_matrix, metric='cosine').reshape(-1))\n",
    "        ]\n",
    "\n",
    "        if closest.lower() == word4.lower():\n",
    "            results[curr_topic]['correct'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capital-common-countries': {'correct': 95, 'total': 506},\n",
      " 'capital-world': {'correct': 284, 'total': 3634},\n",
      " 'city-in-state': {'correct': 16, 'total': 2330},\n",
      " 'currency': {'correct': 3, 'total': 866},\n",
      " 'family': {'correct': 8, 'total': 420},\n",
      " 'gram1-adjective-to-adverb': {'correct': 2, 'total': 992},\n",
      " 'gram2-opposite': {'correct': 5, 'total': 756},\n",
      " 'gram3-comparative': {'correct': 46, 'total': 1332},\n",
      " 'gram4-superlative': {'correct': 8, 'total': 992},\n",
      " 'gram5-present-participle': {'correct': 1, 'total': 1056},\n",
      " 'gram6-nationality-adjective': {'correct': 192, 'total': 1599},\n",
      " 'gram7-past-tense': {'correct': 20, 'total': 1560},\n",
      " 'gram8-plural': {'correct': 18, 'total': 1332},\n",
      " 'gram9-plural-verbs': {'correct': 11, 'total': 870}}\n"
     ]
    }
   ],
   "source": [
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
